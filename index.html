<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="VA-π: Variational Policy Alignment for Pixel-Aware Autoregressive Generation. A lightweight post-training framework that aligns autoregressive visual generators with a principled pixel-space objective.">
  <meta name="theme-color" content="#f7f8fb">

  <!-- Open Graph -->
  <meta property="og:type" content="website">
  <meta property="og:title" content="VA-π: Variational Policy Alignment for Pixel-Aware Autoregressive Generation">
  <meta property="og:description" content="A lightweight post-training framework that aligns autoregressive visual generators with a principled pixel-space objective.">
  <meta property="og:image" content="static/img/teaser.png">
  <meta property="og:url" content="https://va-pi.github.io/">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="VA-π: Variational Policy Alignment for Pixel-Aware Autoregressive Generation">
  <meta name="twitter:description" content="A lightweight post-training framework that aligns autoregressive visual generators with a principled pixel-space objective.">
  <meta name="twitter:image" content="static/img/teaser.png">

  <link rel="canonical" href="https://va-pi.github.io/">
  <link rel="icon" href="static/img/favicon.svg" type="image/svg+xml">
  <title>VA-π: Variational Policy Alignment for Pixel-Aware Autoregressive Generation</title>
  <link rel="stylesheet" href="static/css/style.css">
  <script defer src="static/js/main.js"></script>
</head>
<body>
  <div class="paper" id="top">
    <!-- Sticky TOC (desktop) -->
    <nav class="toc navlinks" aria-label="Table of contents">
      <div class="toc-title">Contents</div>
      <a href="#overview">Overview</a>
      <a href="#observations">Observations</a>
      <a href="#quant-results-ablation">Quantitative Results (C2I/T2I, Ablation)</a>
      <a href="#quant-results">Quantitative Results (C2I/T2I)</a>
    </nav>

    <header class="paper-header">
      <div class="paper-header-inner">
        <h1 class="paper-title">VA-π: Variational Policy Alignment for Pixel-Aware Autoregressive Generation</h1>

        <div class="paper-authors">
          <a href="https://lil-shake.github.io/" target="_blank" rel="noopener">Xinyao Liao</a><sup>*1</sup>,
          <a href="https://qy-h00.github.io/" target="_blank" rel="noopener">Qiyuan He</a><sup>*†2</sup>,
          <a href="https://kai422.github.io/" target="_blank" rel="noopener">Kai Xu</a><sup>2</sup>,
          <a href="https://scholar.google.com/citations?user=rT3hqdcAAAAJ&hl=zh-CN" target="_blank" rel="noopener">Xiaoye Qu</a><sup>1</sup>,
          <a href="https://yl3800.github.io/" target="_blank" rel="noopener">Yicong Li</a><sup>2</sup>,
          <a href="https://www.eric-weiwei.com/" target="_blank" rel="noopener">Wei Wei</a><sup>1</sup>,
          <a href="https://www.comp.nus.edu.sg/~ayao/" target="_blank" rel="noopener">Angela Yao</a><sup>2</sup>
        </div>

        <div class="paper-affiliations">
          <span><sup>1</sup>Huazhong University of Science and Technology</span>
          <span><sup>2</sup>National University of Singapore</span>
        </div>

        <div class="paper-contrib">
          <span><sup>*</sup>Equal contribution</span>
          <span><sup>†</sup>Project lead</span>
        </div>

        <div class="paper-badges" aria-label="Project links">
          <a class="badge secondary disabled" href="#" aria-disabled="true">arXiv (coming soon)</a>
          <a class="badge" href="https://github.com/Lil-Shake/VA-Pi" target="_blank" rel="noopener">Code</a>
        </div>

        <figure class="paper-teaser" aria-label="Teaser">
          <img src="static/img/vis-c2i-t2i_00.png" alt="VA-π teaser">
        </figure>

        <div class="tldr-section">
          <p><span class="tldr-label">TL;DR:</span> How should visual autoregressive models be optimized?
            <b>Token space or pixel space?</b> We argue the answer is pixel space.
            We propose <b>VA-π</b>, a lightweight post-training framework that directly optimizes <b>visual autoregressive models</b> with a principled <b>pixel-space objective</b>!
            <!-- , solved by introducing <b>evidence lower bound (ELBO)</b> that unifies pixel reconstruction and autoregressive modeling.
            To optimize under the discrete token space, VA-π introduces a <b>RL-based alignment strategy</b> that treats the AR generator as a policy, uses pixel-space reconstruction quality as its intrinsic reward and Next Token Prediction (NTP) loss with noisy context as regulizer. -->
          </p>
        </div>
      </div>
    </header>

    <main class="paper-main" id="main">
      <section class="paper-section" id="overview">
        <h2>Overview</h2>
        <p>
          <!-- TODO: replace with final paper overview -->
          Autoregressive (AR) visual generation relies on tokenizers to map images to and from <b>discrete sequences</b>.  However, tokenizers are trained to reconstruct clean images from ground-truth tokens, while AR generators are optimized only for <b>token likelihood</b>. This misalignment leads to generated token sequences that may decode into <b>low-quality images</b>, without direct supervision from the pixel space. 

          Specifically, we propose <b>VA-π</b>, a lightweight post-training framework that directly optimizes AR models with a principled <b>pixel-space objective</b>. VA-π formulates the generator–tokenizer alignment as a variational optimization, deriving an <b>evidence lower bound (ELBO)</b> that unifies <b>pixel reconstruction and autoregressive modeling</b>. To optimize under the discrete token space, VA-π introduces a <b>RL-based alignment strategy</b> that treats the AR generator as a policy, uses pixel-space reconstruction quality as its intrinsic reward. The reward is measured by how well the predicted token sequences can reconstruct the original image under teacher forcing, giving the model direct pixel-level guidance without expensive free-running sampling. The regularization term of the ELBO serves as a natural regularizer, maintaining distributional consistency of tokens. 
        </p>
        <figure class="paper-figure" aria-label="Method overview">
          <img src="static/img/method.png" alt="Method Overview">
          <figcaption>Overview of the VA-π method.</figcaption>
        </figure>
      </section>

      <section class="paper-section" id="observations">
        <h2>Observations</h2>

        <h3 id="obs-alignment-to-pixel-space">1. Alignment to pixel-space</h3>
        <p>
          <!-- TODO: replace with final text -->
          VA-π aligns autoregressive image generation with the ground-truth distribution in pixel space. Qualitatively, VA-π corrects off-manifold token sequences that decode into distorted structures, producing more coherent and faithful reconstructions. Quantitatively, both <b>embedding density estimation (KDE)</b> and <b>low-dimensional projections (t-SNE)</b> show that VA-π shifts generated images closer to the ground-truth manifold.
        </p>
        <figure class="paper-figure" aria-label="Observation 1 teaser">
          <img src="static/img/obs-1.png" alt="Alignment to Pixel Space teaser">
          <figcaption>VA-π brings autoregressive generations closer to the ground-truth image manifold in both appearance and distribution.</figcaption>
        </figure>

        <h3 id="obs-better-than-naive">2. VA-π is better than naive post-train</h3>
        <p>
          We benchmark VA-π against naive post-training baselines on two representative settings:
          <b>class-to-image</b> generation on <b>ImageNet-1K</b> (LlamaGen-XL/XXL; evaluated with and without CFG),
          and <b>text-to-image</b> reasoning on <b>GenEval</b> (LlamaGen-XL and the unified multimodal model Janus-Pro 1B).
          We report standard generation metrics (FID/IS/Precision/Recall for C2I; GenEval sub-scores and overall for T2I) and
          include tuning time and whether an <b>external reward</b> is used.
        </p>
        <ul class="bullet-highlights">
          <li><b>Fast, lightweight gains.</b> Without external reward, VA-π improves LlamaGen-XXL on ImageNet-1K from <b>FID 14.36 → 7.65</b> (w/o CFG) in <b>25 minutes</b>, and improves LlamaGen-XL from <b>FID 15.55 → 9.23</b> in <b>20 minutes</b>.</li>
          <li><b>Better quality at low cost.</b> VA-π boosts perceptual quality significantly: for LlamaGen-XXL (w/o CFG) <b>IS 86.55 → 116.70</b>, and for LlamaGen-XL (w/o CFG) <b>IS 79.16 → 111.59</b>; with CFG it reaches <b>IS 299.63</b> on LlamaGen-XL while still keeping tuning time at <b>20 minutes</b>.</li>
          <li><b>Generalizes beyond C2I.</b> On GenEval, VA-π improves LlamaGen-XL overall from <b>0.306 → 0.339</b>, and also improves the unified multimodal model Janus-Pro 1B from <b>0.725 → 0.744</b>.</li>
        </ul>

        <figure class="paper-table" aria-label="C2I quantitative results table">
          <div class="table-scroll" role="region" aria-label="Scrollable table">
            <table>
              <thead>
                <tr>
                  <th rowspan="2" style="text-align:left;">Model</th>
                  <th rowspan="2">Ext. Rwd</th>
                  <th rowspan="2">Time (min) ↓</th>
                  <th colspan="4">w/o cfg</th>
                  <th colspan="4">w/ cfg</th>
                </tr>
                <tr>
                  <th>FID ↓</th><th>IS ↑</th><th>Pre. ↑</th><th>Rec. ↑</th>
                  <th>FID ↓</th><th>IS ↑</th><th>Pre. ↑</th><th>Rec. ↑</th>
                </tr>
              </thead>
              <tbody>
                <tr class="row-group">
                  <td style="text-align:left;"><b>LlamaGen-XL (775M)</b></td>
                  <td>--</td><td>--</td>
                  <td>15.55</td><td>79.16</td><td>0.62</td><td>0.69</td>
                  <td class="hl">2.79</td><td>286.88</td><td>0.84</td><td>0.54</td>
                </tr>
                <tr>
                  <td style="text-align:left;">&nbsp;&nbsp;+ AR-GRPO</td>
                  <td>✓</td><td>149</td>
                  <td>--</td><td>--</td><td>--</td><td>--</td>
                  <td>3.63</td><td>293.07</td><td>0.86</td><td>0.48</td>
                </tr>
                <tr>
                  <td style="text-align:left;">&nbsp;&nbsp;+ <b>VA-π (Ours)</b></td>
                  <td>×</td><td>20</td>
                  <td class="hl">9.23</td><td class="hl">111.59</td><td>0.71</td><td>0.59</td>
                  <td>2.94</td><td class="hl">299.63</td><td>0.84</td><td>0.53</td>
                </tr>

                <tr class="sep"><td colspan="11"></td></tr>

                <tr class="row-group">
                  <td style="text-align:left;"><b>LlamaGen-XXL (1.4B)</b></td>
                  <td>--</td><td>--</td>
                  <td>14.36</td><td>86.55</td><td>0.63</td><td>0.69</td>
                  <td>2.37</td><td>252.16</td><td>0.81</td><td>0.59</td>
                </tr>
                <tr>
                  <td style="text-align:left;">&nbsp;&nbsp;+ Post-train Tokenizer</td>
                  <td>×</td><td>18</td>
                  <td>14.26</td><td>86.70</td><td>0.63</td><td>0.68</td>
                  <td>2.72</td><td>246.97</td><td>0.80</td><td>0.59</td>
                </tr>
                <tr>
                  <td style="text-align:left;">&nbsp;&nbsp;+ Post-train Tokenizer (longer)</td>
                  <td>×</td><td>207</td>
                  <td>22.99</td><td>72.49</td><td>0.56</td><td>0.68</td>
                  <td>4.31</td><td>221.57</td><td>0.75</td><td>0.58</td>
                </tr>
                <tr>
                  <td style="text-align:left;">&nbsp;&nbsp;+ STE based Post-train AR</td>
                  <td>×</td><td>381</td>
                  <td>11.46</td><td>102.21</td><td>0.68</td><td>0.61</td>
                  <td>4.17</td><td>267.34</td><td>0.83</td><td>0.51</td>
                </tr>
                <tr>
                  <td style="text-align:left;">&nbsp;&nbsp;+ <b>VA-π (Ours)</b></td>
                  <td>×</td><td>25</td>
                  <td class="hl">7.65</td><td class="hl">116.70</td><td>0.71</td><td>0.64</td>
                  <td class="hl">2.28</td><td class="hl">273.53</td><td>0.83</td><td>0.56</td>
                </tr>
              </tbody>
            </table>
          </div>
          <figcaption>C2I: ImageNet-1K class-conditional quantitative results.</figcaption>
        </figure>

        <figure class="paper-table" aria-label="T2I GenEval results table">
          <div class="table-scroll" role="region" aria-label="Scrollable table">
            <table>
              <thead>
                <tr>
                  <th style="text-align:left;">Model</th>
                  <th>Ext. Rwd</th>
                  <th>Position ↑</th>
                  <th>Color ↑</th>
                  <th>Attr. Bind. ↑</th>
                  <th>Counting ↑</th>
                  <th>Single Obj. ↑</th>
                  <th>Two Obj. ↑</th>
                  <th>Overall ↑</th>
                </tr>
              </thead>
              <tbody>
                <tr class="row-group">
                  <td style="text-align:left;"><b>LlamaGen-XL</b></td>
                  <td>--</td>
                  <td>0.042</td><td>0.550</td><td>0.032</td><td>0.197</td><td>0.750</td><td>0.263</td><td>0.306</td>
                </tr>
                <tr>
                  <td style="text-align:left;">&nbsp;&nbsp;+ AR-GRPO</td>
                  <td>✓</td>
                  <td>0.040</td><td>0.593</td><td>0.030</td><td>0.228</td><td class="hl">0.791</td><td>0.263</td><td>0.324</td>
                </tr>
                <tr>
                  <td style="text-align:left;">&nbsp;&nbsp;+ <b>VA-π (Ours)</b></td>
                  <td>×</td>
                  <td class="hl">0.050</td><td class="hl">0.606</td><td class="hl">0.040</td><td class="hl">0.238</td><td>0.769</td><td class="hl">0.328</td><td class="hl">0.339</td>
                </tr>

                <tr class="sep"><td colspan="9"></td></tr>

                <tr class="row-group">
                  <td style="text-align:left;"><b>Janus-Pro 1B</b></td>
                  <td>-</td>
                  <td class="hl">0.605</td><td>0.902</td><td>0.540</td><td>0.531</td><td>0.972</td><td>0.801</td><td>0.725</td>
                </tr>
                <tr>
                  <td style="text-align:left;">&nbsp;&nbsp;+ <b>VA-π (Ours)</b></td>
                  <td>×</td>
                  <td>0.600</td><td class="hl">0.912</td><td class="hl">0.585</td><td class="hl">0.540</td><td class="hl">0.988</td><td class="hl">0.835</td><td class="hl">0.744</td>
                </tr>
              </tbody>
            </table>
          </div>
          <figcaption>T2I: GenEval quantitative results.</figcaption>
        </figure>
      </section>

      <section class="paper-section" id="quant-results-ablation">
        <h2>Quantitative Results (C2I/T2I, Ablation Study)</h2>
        <p class="section-note">
          <!-- TODO -->
          Report ablations for both class-to-image (C2I) and text-to-image (T2I) settings.
        </p>
        <div class="table-placeholder" aria-label="Ablation tables placeholder">
          <div class="placeholder-note">[Place C2I + T2I ablation tables here]</div>
        </div>
      </section>

      <section class="paper-section" id="quant-results">
        <h2>Quantitative Results (C2I/T2I)</h2>
        <p class="section-note">
          <!-- TODO -->
          Main quantitative results for both C2I and T2I benchmarks.
        </p>
        <div class="table-placeholder" aria-label="Main results tables placeholder">
          <div class="placeholder-note">[Place C2I + T2I main results tables/plots here]</div>
        </div>
      </section>

      <section class="paper-section" id="citation">
        <h2>Citation</h2>
        <p class="note">Update the BibTeX below once the paper/arXiv entry is finalized.</p>
        <div class="codebox">
          <div class="codebox-head">
            <div class="codebox-title">BibTeX</div>
            <button class="copy-btn" type="button" data-copy-target="#bibtex">Copy</button>
          </div>
          <pre class="codeblock"><code id="bibtex">@article{vapi2025,
  title   = {VA-\\pi: Variational Policy Alignment for Pixel-Aware Autoregressive Generation},
  author  = {Liao, Xinyao and He, Qiyuan and Xu, Kai and Qu, Xiaoye and Li, Yicong and Wei, Wei and Yao, Angela},
  journal = {arXiv preprint arXiv:????.?????},
  year    = {2025}
}</code></pre>
        </div>
      </section>
    </main>
  </div>
</body>
</html>
